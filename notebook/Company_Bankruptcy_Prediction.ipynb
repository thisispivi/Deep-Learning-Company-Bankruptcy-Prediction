{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Company Bankruptcy Prediction",
      "provenance": [],
      "collapsed_sections": [
        "LigW-AsMEbri",
        "3S5hOmIGEs9j"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ve8CgpE1BAA"
      },
      "source": [
        "# Introduction\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y3W5qXWABYT"
      },
      "source": [
        "# Dataset and Libraries setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ufwrliP-uJK"
      },
      "source": [
        "##Libraries and Dataset setup\n",
        "\n",
        "Download the dataset and the libraries needed.\n",
        "\n",
        "**Libraries**\n",
        "- pandas\n",
        "- numpy\n",
        "- kaggle\n",
        "- plotly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1Mh9Ol_I88j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c466676-6a7c-4952-8cad-71415ad0e0ae"
      },
      "source": [
        "### Download files\n",
        "! apt-get update > /dev/null\n",
        "! apt-get upgrade > /dev/null\n",
        "! apt-get install unzip > /dev/nulll\n",
        "\n",
        "# Python libs\n",
        "! pip install -q kaggle > /dev/null\n",
        "! pip install plotly==4.14.3 > /dev/null\n",
        "! pip install -U kaleido > /dev/null"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting templates from packages: 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0tklqOA8XhC"
      },
      "source": [
        "Import plot and other useful libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a86cMyQNGKAC"
      },
      "source": [
        "### Import section\n",
        "\n",
        "# Plot\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Others\n",
        "import csv\n",
        "from io import StringIO\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOSH7YCE-7Qe"
      },
      "source": [
        "##Import dataset\n",
        "There are two ways to download the dataset, one from kaggle using kaggle api the other one from github (the dataset may be out of date)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87mmzkepfj6f"
      },
      "source": [
        "### Delete old folders and create new ones\n",
        "! rm -r /content/data > /dev/null\n",
        "! mkdir /content/data/ > /dev/null\n",
        "! rm -r ~/.kaggle > /dev/null\n",
        "! mkdir ~/.kaggle > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vkJnrG5fqat"
      },
      "source": [
        "### Kaggle\n",
        "\n",
        "Connect to kaggle, download datataset and setup the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TknXpMfPcCvM"
      },
      "source": [
        "### Kaggle download setup \n",
        "\n",
        "# Insert here the link to the token json file\n",
        "! wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-4sfcaQg3DdP6ZoRnm0uFvM5VlMhPDSM' -P /content -O kaggle.json > /dev/null\n",
        "\n",
        "# Copy token in the right folder\n",
        "! cp kaggle.json ~/.kaggle/ > /dev/null\n",
        "! chmod 600 ~/.kaggle/kaggle.json > /dev/null\n",
        "\n",
        "# Download dataset\n",
        "! kaggle datasets download -d fedesoriano/company-bankruptcy-prediction -p /content/data > /dev/null\n",
        "\n",
        "# Unzip and remove the zip\n",
        "! unzip /content/data/company-bankruptcy-prediction.zip -d /content/data > /dev/null\n",
        "! rm /content/data/company-bankruptcy-prediction.zip > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKQG2puuftem"
      },
      "source": [
        "### Github\n",
        "Connect to Github, download datataset and setup the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7dIhEHgCp5R"
      },
      "source": [
        "# ### Download dataset from github repository\n",
        "\n",
        "# # Donwload all the files\n",
        "# ! wget -P /content/data https://raw.githubusercontent.com/thisispivi/Deep-Learning-Company-Bankruptcy-Prediction/main/data/data.zip\n",
        "\n",
        "# # Unzip and remove the zip\n",
        "# ! unzip /content/data/data.zip -d /content/data\n",
        "# ! rm /content/data/data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7774NYzghPEm"
      },
      "source": [
        "## Read Files\n",
        "In this section we import the csv files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HANip0NiQt2C"
      },
      "source": [
        "df = pd.read_csv('data/data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4zXPeyvVUGZ"
      },
      "source": [
        "Split the dataset into labela and data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg3dFnarVVez"
      },
      "source": [
        "labels = df['Bankrupt?']\n",
        "data = df.drop(['Bankrupt?'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaafBVnEiBU9"
      },
      "source": [
        "# Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3fhXvQzl7yL"
      },
      "source": [
        "## Import Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL5L7D2zs09v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbc4e85f-bcb1-419e-85ef-8b4363209375"
      },
      "source": [
        "from tensorflow import keras\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ByxXiGECxOP"
      },
      "source": [
        "## Analyze dataset\n",
        "\n",
        "In this section we will analyze the dataset shape, balance and if it has null values in its rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXBfjRRNUn8F"
      },
      "source": [
        "### Shape\n",
        "\n",
        "Check the shape of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "wNXUUbicUpkH",
        "outputId": "d69be9ef-9b8e-4354-d05e-0abea13512d6"
      },
      "source": [
        "print('Data shape:', data.shape)\n",
        "print('Labels shape:', labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c0c41d79f146>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data shape:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Labels shape:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl0rlZn7Czva"
      },
      "source": [
        "### Null values\n",
        "\n",
        "Check if there are null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq_W39eICzfe"
      },
      "source": [
        "df.isnull().sum(axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBKSE6hTDjxF"
      },
      "source": [
        "There are no null values so we don't have to deal with them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-MA_ExoC-Cd"
      },
      "source": [
        "### Balance\n",
        "\n",
        "Check if the dataset is balanced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtctIj3sEAX4"
      },
      "source": [
        "result = df['Bankrupt?'].value_counts()\n",
        "zero_percentage = round((result[0]*100)/(result[0]+result[1]),2)\n",
        "print(\"No. of 0: \"+ str(result[0]) + \"\\nNo. of 1: \" + str(result[1]) + \n",
        "      \"\\nPercentage of 0: \"+ str(zero_percentage)+ \" %\\nPercentage of 1: \"+\n",
        "      str(round((100-zero_percentage),2))+\" %\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lRuuDNoIgqG"
      },
      "source": [
        "plt.bar(x=[\"No Bankrupt\", \"Bankrupt\"], height=[result[0], result[1]], color=[\"royalblue\", \"indianred\"])\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Number of No Bankrupt rows vs number of Bankrupt rows \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baJNHjoZLQC9"
      },
      "source": [
        "plt.pie([result[0], result[1]], labels=[\"No Bankrupt\", \"Bankrupt\"], explode=(0.1, 0), autopct='%1.2f%%', colors=[\"thistle\", \"paleturquoise\"], radius=1.2)\n",
        "plt.title(\"Percentage of No Bankrupt vs percentage of Bankrupt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8Tnp6CKETkF"
      },
      "source": [
        "The dataset is not balanced. If we don't fix this when we will run the model we will have a perfect accuracy, because the network will concentrate only on the major class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4N9IuKrPv6dc"
      },
      "source": [
        "## Normalize values\n",
        "\n",
        "In this section we want to normalize the values, so we take the colums with values over 1 and with values less than 0 and we normalize them using *StandardScaler()*. This scaler uses the mean and the standard deviation to set all values to between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzS8wHoovV01"
      },
      "source": [
        "### Normalize values\n",
        "\n",
        "# Take the columns with values over 1\n",
        "cols_for_scale = df.max()[df.max()>1]\n",
        "# Take the columns with values less than 0\n",
        "df.min()[df.min()<0] # It is none there aren't negative values\n",
        "# Normalize values\n",
        "scale = StandardScaler()\n",
        "scaled = scale.fit_transform(df[cols_for_scale.keys()])\n",
        "# Substitute the old values with the normalized ones\n",
        "i = 0\n",
        "for column in cols_for_scale.keys():\n",
        "    df[column] = scaled[:,i]\n",
        "    i += 1\n",
        "# Update labels and data\n",
        "labels = df['Bankrupt?']\n",
        "data = df.drop(['Bankrupt?'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTRYvzAzC8yN"
      },
      "source": [
        "## Balance Dataset using SMOTE\n",
        "To balance the dataset we use SMOTE (Synthetic Minority Oversampling Technique).\n",
        "\n",
        "[Link](https://towardsdatascience.com/applying-smote-for-class-imbalance-with-just-a-few-lines-of-code-python-cdf603e58688)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-8SD1X0Ufwp"
      },
      "source": [
        "Import SMOTE and resample the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0iLTb2rPEnX"
      },
      "source": [
        "sm = SMOTE()\n",
        "data_new, labels_new = sm.fit_resample(data, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U83pBYB3UixY"
      },
      "source": [
        "Check the shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RtSsx2ARwlt"
      },
      "source": [
        "print('Data shape:', data_new.shape)\n",
        "print('Labels shape:', labels_new.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVkhRUsSSfSa"
      },
      "source": [
        "new_df = pd.DataFrame(labels_new)\n",
        "result = new_df[0].value_counts()\n",
        "zero_percentage = round((result[0]*100)/(result[0]+result[1]),2)\n",
        "print(\"No. of 0: \"+ str(result[0]) + \"\\nNo. of 1: \" + str(result[1]) + \n",
        "      \"\\nPercentage of 0: \"+ str(zero_percentage)+ \" %\\nPercentage of 1: \"+\n",
        "      str(round((100-zero_percentage),2))+\" %\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFvR-x-LSfSb"
      },
      "source": [
        "plt.bar(x=[\"No Bankrupt\", \"Bankrupt\"], height=[result[0], result[1]], color=[\"royalblue\", \"indianred\"])\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Number of No Bankrupt rows vs number of Bankrupt rows \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOeeoRGISfSb"
      },
      "source": [
        "plt.pie([result[0], result[1]], labels=[\"No Bankrupt\", \"Bankrupt\"], explode=(0.1, 0), autopct='%1.2f%%', colors=[\"thistle\", \"paleturquoise\"], radius=1)\n",
        "plt.title(\"Percentage of No Bankrupt vs percentage of Bankrupt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQSN7MiSSfSb"
      },
      "source": [
        "As we can see the dataset is perfectly balanced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwlFckFIwPf0"
      },
      "source": [
        "## Split data into training, validation and test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F0NMf7aBx-k"
      },
      "source": [
        "Split the data in:\n",
        "* x_train: The training set data\n",
        "* y_train: The training set label\n",
        "* x_valid: The validation set data\n",
        "* y_valid: The validation set label\n",
        "* x_test: The validation set data\n",
        "* y_test: The validation set label\n",
        "\n",
        "The dimension will be something like\n",
        "\n",
        "* Training: 70%\n",
        "* Validation: 20%\n",
        "* Test: 10%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1KcVasVwSs5"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(data_new, labels_new, train_size=0.9)\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, train_size=0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTahAzZJCtcs"
      },
      "source": [
        "Print all the sizes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlMm2IwKwugb"
      },
      "source": [
        "print('Train data shape:', x_train.shape)\n",
        "print('Train labels shape:', y_train.shape)\n",
        "print('Validation data shape:', x_valid.shape)\n",
        "print('Validation labels shape:', y_valid.shape)\n",
        "print('Test data shape:', x_test.shape)\n",
        "print('Test labels shape:', y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60HT1pwCxI0F"
      },
      "source": [
        "## Create New Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "691U7JYNE_a0"
      },
      "source": [
        "### Options\n",
        "\n",
        "In this section there are some boolean variables to tune what the code will do:\n",
        "\n",
        "* train_model -> True: the network will be trained / False: network wont' be trained\n",
        "* model_loss -> True: plot the model loss / False: don't plot the model loss\n",
        "* model_accuracy -> True: plot the model accuracy / False: don't plot the model accuracy\n",
        "* evaluate_model -> True: evaluate the model / False: don't evaluate the model\n",
        "* conf_matr -> True: plot the confusion matrix / False: don't plot the confusion matrix\n",
        "* plot_model -> True: plot the structure of the network / False: don't plot the structure of the network\n",
        "* save_model -> True: save the model / False: don't save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoljJF-6E__7"
      },
      "source": [
        "train_model = True\n",
        "model_loss = True\n",
        "model_accuracy = True\n",
        "evaluate_model = True\n",
        "conf_matr = True\n",
        "plot_model = True\n",
        "save_model = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ5uNrhyEXu-"
      },
      "source": [
        "### Create the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orkv-WlKxLBp"
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(128, activation='relu', input_shape=(95,)))\n",
        "model.add(keras.layers.Dense(64,kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(32,kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(16,kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "optimizer = keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LigW-AsMEbri"
      },
      "source": [
        "### Train the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9EaKz5dzOeL"
      },
      "source": [
        "if train_model == True:\n",
        "  history = model.fit(x_train, y_train, epochs=200, validation_data=(x_valid,y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlX82DsKEdvq"
      },
      "source": [
        "### Loss graph of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSuKLOb4Av18"
      },
      "source": [
        "if model_loss == True:\n",
        "  plt.subplots(figsize=(12,8))\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('Model Loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S5hOmIGEs9j"
      },
      "source": [
        "### Accuracy graph of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKWN9djLyMc7"
      },
      "source": [
        "if model_accuracy == True:\n",
        "  plt.subplots(figsize=(12,8))\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('Model Accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAGewXYAEwD3"
      },
      "source": [
        "### Evaluate the model\n",
        "\n",
        "Check how well the dataset perform on the test set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzswDSgvz64p"
      },
      "source": [
        "if evaluate_model == True:\n",
        "  model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocROaziSE4et"
      },
      "source": [
        "### Confusion Matrix\n",
        "\n",
        "Compute the label prediction using the test set and plot the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNA7s8vOEQh0"
      },
      "source": [
        "if conf_matr == True:\n",
        "  predictions = model.predict(x_test)\n",
        "  classes = predictions > 0.5\n",
        "  cm = confusion_matrix(y_test,classes)\n",
        "\n",
        "  # Plot\n",
        "  plt.figure(figsize=(10,7))\n",
        "  ax = plt.subplot()\n",
        "  sns.heatmap(cm, annot=True, fmt='g', ax=ax, cmap=\"PuBu\");  # annot=True to annotate cells, ftm='g' to disable scientific notation\n",
        "  ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "  ax.set_title('Confusion Matrix'); \n",
        "  ax.xaxis.set_ticklabels(['No Bankrupt', 'Bankrupt']); ax.yaxis.set_ticklabels(['No Bankrupt', 'Bankrupt']);\n",
        "  print(classification_report(y_test,classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ksCcMAVKwK7"
      },
      "source": [
        "### Test performance original dataset\n",
        "\n",
        "Here we see how the network performs on the dataset unmodified by the SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHbweMsjJHgR"
      },
      "source": [
        "x_original_train, x_original_test, y_original_train, y_original_test = train_test_split(data, labels, train_size=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Td_HcD95fyx0"
      },
      "source": [
        "#### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzXDhKHqJrMm"
      },
      "source": [
        "if conf_matr == True:\n",
        "  predictions = model.predict(x_original_test)\n",
        "  classes = predictions > 0.5\n",
        "  cm = confusion_matrix(y_original_test,classes)\n",
        "\n",
        "  # Plot\n",
        "  plt.figure(figsize=(10,7))\n",
        "  ax = plt.subplot()\n",
        "  sns.heatmap(cm, annot=True, fmt='g', ax=ax, cmap=\"PuBu\");  # annot=True to annotate cells, ftm='g' to disable scientific notation\n",
        "  ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "  ax.set_title('Confusion Matrix'); \n",
        "  ax.xaxis.set_ticklabels(['No Bankrupt', 'Bankrupt']); ax.yaxis.set_ticklabels(['No Bankrupt', 'Bankrupt']);\n",
        "  print(classification_report(y_test,classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi5S7LhQTexS"
      },
      "source": [
        "### Plot model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1ny8y9KThbB"
      },
      "source": [
        "if plot_model == True:\n",
        "  dot_img_file = \"network.png\"\n",
        "  keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RZ5X7kXE0XD"
      },
      "source": [
        "### Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyLclhdA5VDW"
      },
      "source": [
        "if save_model == True:\n",
        "  file_name = 'acc_97'\n",
        "  model.save(file_name)\n",
        "\n",
        "# ! zip -r model.zip acc_97/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq2wNkY2_W2c"
      },
      "source": [
        "## Load the model\n",
        "\n",
        "Load on colab the model.zip file. Uncomment to use this section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERK8LG-UtAV_"
      },
      "source": [
        "Unzip the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sCAWqEftCJQ"
      },
      "source": [
        "# ! unzip model.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_i3FK_XzsRCM"
      },
      "source": [
        "Import the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnS1lowBsPRe"
      },
      "source": [
        "# file_name = 'acc_97'\n",
        "# model = keras.models.load_model(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}